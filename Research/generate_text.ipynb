{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f91ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204c004a292b4498ac5187a8c0847dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d514f2854a4c4ab6840915125f00c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1c7754dd2d4150b56689013285bba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc30c856d6a741348f432d4c4f983434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe99d99b18d42c99aecb8ccc9b28ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43bb4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|endoftext|>', 50256)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token,tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89ede912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99798498bf4c436182536d7efdc85927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbab286c50646749b60eea97ebdfde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a6b238a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   40,  2883,  6155,   351,   616, 13779,  3290]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer('I enjoy walking with my cute dog', return_tensors='pt').to(torch_device)\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b700b",
   "metadata": {},
   "source": [
    "## Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd23e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   40,  2883,  6155,   351,   616, 13779,  3290,    11,   475,   314,\n",
       "          1101,   407,  1654,   611,   314,  1183,  1683,   307,  1498,   284,\n",
       "          2513,   351,   616,  3290,    13,   314,  1101,   407,  1654,   611,\n",
       "           314,  1183,  1683,   307,  1498,   284,  2513,   351,   616,  3290,\n",
       "            13,   198,   198,    40,  1101,   407,  1654]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_output = model.generate(**model_inputs, max_new_tokens=40)\n",
    "greedy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a42bf85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
      "\n",
      "I'm not sure\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00fe29",
   "metadata": {},
   "source": [
    "## Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4756b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if I'll ever be able to walk with him again. I'm not sure\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    num_beams=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e44faf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to\n"
     ]
    }
   ],
   "source": [
    "# set no_repeat_ngram_size to 2\n",
    "beam_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    num_beams=5,\n",
    "    no_repeat_ngram_size=2,\n",
    "    early_stopping=True\n",
    ")\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adeb54d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to\n",
      "--------------------\n",
      "1: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to\n",
      "--------------------\n",
      "2: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's a good idea to\n",
      "--------------------\n",
      "3: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time to take a\n",
      "--------------------\n",
      "4: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's a good idea.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# set return_num_sequences > 1\n",
    "beam_outputs = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    num_beams=5,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_return_sequences=5,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# now we have 3 output sequences\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))\n",
    "  print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f913ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I like walking with my dog.\n",
      "--------------------\n",
      "1: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I like walking with my dog,\n",
      "--------------------\n",
      "2: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I like walking with her,\" she\n",
      "--------------------\n",
      "3: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I like walking with my dogs,\"\n",
      "--------------------\n",
      "4: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I don't know if it's\n",
      "--------------------\n",
      "5: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I like walking with my dog and\n",
      "--------------------\n",
      "6: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I like walking with my dog because\n",
      "--------------------\n",
      "7: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I don't know what to say\n",
      "--------------------\n",
      "8: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I don't know if she's\n",
      "--------------------\n",
      "9: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I like walking with my dogs.\n",
      "--------------------\n",
      "10: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I like walking with my dog.\"\n",
      "--------------------\n",
      "11: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I don't know what to do\n",
      "--------------------\n",
      "12: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I like walking with her,\" said\n",
      "--------------------\n",
      "13: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "\n",
      "\"I don't know if I'm\n",
      "--------------------\n",
      "14: I enjoy walking with my cute dog,\" she said.\n",
      "\n",
      "\"I love walking with my dog,\" she added. \"I love walking with her. I love walking with her.\"\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# set return_num_sequences 15\n",
    "beam_outputs = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    num_beams=15,\n",
    "    no_repeat_ngram_size=5,\n",
    "    num_return_sequences=15,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# now we have 15 output sequences\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))\n",
    "  print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a0353",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa0bd5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, Daddy,\" a barter in the popular underground Twitter service Tweston tells Gladstone. \"Like it or not, I've always wanted to dogfeed and cooperate with several others. Being an American\n"
     ]
    }
   ],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "from transformers import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18d2d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, and I was delighted to have him on my show, so I had a chance to see him. I was very impressed with his body, and I am looking forward to seeing what he has to\n"
     ]
    }
   ],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# use temperature to decrease the sensitivity to low probability candidates\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=0,\n",
    "    temperature=0.6,\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bedafef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, which is a little unusual in this part of our family. He's a friendly, calm kind of dog, and I've always wanted to have him around, and I always wanted to go with\n"
     ]
    }
   ],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# set top_k to 50\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6907e774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, Daddy,\" a barter in the popular underground Twitter service Twitchell agreed.\n",
      "\n",
      "Like it or not, \"It's been a while,\" American Indian Salwa Donna Dal made me laugh\n"
     ]
    }
   ],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# set top_k to 50\n",
    "sample_output = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_p=0.92,\n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dd7e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: I enjoy walking with my cute dog, a sweet little fluffy little kitty. It's a very cute dog, but it's a lot of fun! But I'm not ready to walk it! I want to give a lot more\n",
      "1: I enjoy walking with my cute dog and watching movies because it is my favorite thing to do. Being at this facility for five minutes is so much fun.\" â€“ Karen D.\n",
      "\n",
      "The program has inspired several family vacations at Loy\n",
      "2: I enjoy walking with my cute dog,\" said the 14-year-old. \"I always go out with him and have fun.\"\n",
      "\n",
      "As for his relationship with his pet dogs, the 7-year-old said he's\n"
     ]
    }
   ],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "set_seed(42)\n",
    "\n",
    "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "sample_outputs = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=40,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=3,\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e8204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
